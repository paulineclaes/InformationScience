{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Morphology tool\n",
    "Use Whoosh to illustrate English morphology with examples from a given corpus. For instance, the rules of morphology dictate verbs can take different forms or be used to form nouns, adjectives and such, like:\n",
    "\n",
    "- `render`: 'renders', 'rendered', 'rendering'\n",
    "- `think`: 'thinks', 'thought', 'thinking', 'thinker', 'thinkers', 'thinkable'\n",
    "- `put`: 'puts', 'putting', 'putter'\n",
    "- `do`: 'does', 'did', 'done', 'doing', 'doings', 'doer', 'doers'\n",
    "\n",
    "Forms like `think`, `put` and `do` illustrate that you cannot approach this problem in a mechanical or brute-force way. It is not as simple as adding 'ed', 'ing', etcetera to the verbs. Sometimes consonants are doubled, sometimes the verb stem changes (in the case of strong verbs), and so on.\n",
    "\n",
    "Whoosh has a particular feature to deal with this. Look through the documentation and you'll find it easily.\n",
    "\n",
    "Use it to build a Python application that takes a word as input and returns a list of sentences from the British fiction corpus that contain this word to illustrate its usage. Think about building the index first, so you can then reuse it (without having to rebuild it) for additional searches.\n",
    "\n",
    "Also, try to display the results nicely, i.e. without the markup tags and whitespace (line breaks, etc.) we saw in the above example. Maybe you can even print the matched word in bold?\n",
    "\n",
    "illustrate english morphology with examples from a corpus\n",
    "- roots of words can be used to make different forms that are then conjugations of a word or a noun/adjective / ...\n",
    "- whoosh: predict how different variant forms can vary\n",
    "- take the corpus that we have used and make an application that accepts a word \n",
    "- look for the results in the index that we have made for whoosh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://docs.red-dove.com/whoosh/stemming.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.fields import Schema, TEXT, ID\n",
    "schema = Schema(title=TEXT(stored=True),content=TEXT(stored=True),\n",
    "               path=ID(stored=True))\n",
    "\n",
    "import os.path\n",
    "from whoosh.index import create_in\n",
    "\n",
    "if not os.path.exists(\"index\"):\n",
    "    os.mkdir(\"index\")\n",
    "ix = create_in(\"index\", schema)\n",
    "\n",
    "from whoosh.index import open_dir\n",
    "ix = open_dir(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OS_SEP = os.sep\n",
    "#writer = ix.writer()\n",
    "#for document in os.listdir('InformationScience/course/data/corpus_of_british_fiction'): \n",
    "    #with open(document, 'r', encoding='utf-8') as text:\n",
    "        #writer.add_document(title=document,content=str(text.read()),\n",
    "                            #path=document)\n",
    "#writer.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'render'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from whoosh.lang.porter import stem\n",
    "stem('rendering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whoosh.lang.morph_en import variations\n",
    "# variations(\"rendered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = []\n",
    "\n",
    "def query_search():\n",
    "    retry = True\n",
    "    while retry: \n",
    "        look_up = input(\"Look up a word or type q to quit.   \")\n",
    "        if not 'q' in look_up:\n",
    "            query.append(look_up)\n",
    "        if look_up == 'q':\n",
    "            retry=False\n",
    "    if retry == False:\n",
    "        for word in query:\n",
    "            print(word, \"-\", variations(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(to_split):\n",
    "    return to_split.split(' ')\n",
    "\n",
    "def make_word_index(corpus):\n",
    "    index = {}\n",
    "    for title in corpus:\n",
    "        words = split(title)\n",
    "        for word in words:\n",
    "            index.setdefault(word,[])\n",
    "            index[word].append(title)\n",
    "    return index\n",
    "\n",
    "def search_with_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`if _name__ = \"__main__\"`: what does this do?\n",
    "\n",
    "Imagine you're writing a file (script) in which you define a function named test:\n",
    "\n",
    "```python\n",
    "def test():\n",
    "    return \"hello world\"\n",
    "\n",
    "print(test())\n",
    ">>> hello world\n",
    "```\n",
    "\n",
    "if you then make a second file and you want to use the code that you have written in first file:\n",
    "\n",
    "```python\n",
    "import test\n",
    "print(test.test())\n",
    ">>> hello world\n",
    "hello world \n",
    "```\n",
    ">>> hello world is printed twice. Because first of all you go to the test module and execute the function 'test', but also by importing test, you're importing the whole file and importing the code that is in there, and this is something that you don't want\n",
    "- you wnat to be able to execute those functions in your own file\n",
    "- you do this by `if __name__=__main__`, and it will not double execute the code in the import file so it will only print 'hello world' once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generators\n",
    "(code on github)\n",
    "- function that does the same as making the list yourself, but it doesn't return the list, but it returns a number: it returns the list number by number\n",
    "- they allow you to use them just as you would use a list, you don't need to keep track of where you are, you can just iterate over them just as you can iterate over a list\n",
    "- the next time you go to the generator, it will go to the next number of that range\n",
    "- you don't yield a list, but you will yield it number by number\n",
    "- if you were to make a list of 10 million items/numbers, it would take up the entire memory of your computer\n",
    "- but a generator takes it number by number\n",
    "\n",
    "In our code: \n",
    "- we don't want to fill up our memory\n",
    "- we want to yield hit by hit and get those sentences back\n",
    "- define a generator for this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Try to do time-intensive operations like building an index only once in your code\n",
    "2. Try to write code that is cross-platform, or at least does not break when executed on a different platform than yours\n",
    "3. Especially for data science: account for large data structures\n",
    "4. In Python everything is an object: all of the modules in the Whoosh library returned an object with its own specific methods. Understanding this OOP design of Python will help a lot when reading documentation for external libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
