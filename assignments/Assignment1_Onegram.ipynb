{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('corpus.txt', 'r') as f: \n",
    "    book = f.read()\n",
    "    corpus = book.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14303), ('of', 6611), ('and', 6277), ('a', 4635), ('to', 4576), ('in', 4076), ('that', 2754), ('his', 2485), ('it', 1781), ('i', 1725), ('as', 1711), ('with', 1709), ('he', 1681), ('but', 1673), ('is', 1601), ('was', 1578), ('for', 1553), ('all', 1351), ('at', 1309), ('this', 1275), ('by', 1183), ('from', 1097), ('not', 1074), ('be', 1000), ('on', 964), ('so', 883), ('you', 826), ('one', 790), ('had', 763), ('have', 759), ('or', 739), ('were', 650), ('they', 643), ('their', 619), ('some', 608), ('an', 592), ('are', 586), ('my', 575), ('like', 565), ('which', 559), ('upon', 556), ('him', 555), ('when', 551), ('whale', 530), ('into', 520), ('there', 503), ('now', 502), ('no', 486), ('what', 477), ('if', 466), ('out', 442), ('we', 441), ('more', 438), ('old', 425), ('up', 423), ('would', 417), ('been', 401), ('these', 383), ('its', 376), ('then', 373), ('over', 367), ('only', 364), ('other', 360), ('such', 359), ('will', 353), ('me', 342), ('any', 329), ('very', 312), ('though', 311), ('than', 310), ('down', 306), ('those', 304), ('great', 292), ('has', 286), ('still', 283), ('about', 281), ('most', 281), ('her', 277), ('them', 274), ('seemed', 273), ('yet', 273), ('who', 272), ('must', 272), ('two', 268), ('ye', 267), ('long', 263), ('do', 260), ('your', 258), ('before', 258), ('after', 254), ('said', 249), ('man', 242), ('white', 240), ('it,', 237), ('ahab', 235), ('little', 234), ('him,', 233), ('ship', 231), ('did', 231), ('thou', 230)]\n"
     ]
    }
   ],
   "source": [
    "def freq_dict(text):\n",
    "    d = {}\n",
    "    text = text.split()\n",
    "    for word in text: \n",
    "        if word in d: \n",
    "            d[word] += 1\n",
    "        else: \n",
    "            d[word] = 1\n",
    "    return d\n",
    "\n",
    "fd = freq_dict(corpus)\n",
    "\n",
    "from operator import itemgetter\n",
    "sorted_freq = sorted(fd.items(), key=itemgetter(1), reverse=True)\n",
    "print(sorted_freq[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prof. Deneire's code: \n",
    "import unicodedata\n",
    "\n",
    "def clean(to_clean:str) -> str: \n",
    "    for punc in \"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\n\":\n",
    "        check = to_clean.count(punc)\n",
    "        if check: \n",
    "            to_clean = to_clean.replace(punc, \" \", check)\n",
    "    return to_clean\n",
    "\n",
    "def normalize(word:str) -> str: \n",
    "    word = word.casefold()\n",
    "    word = word.strip()\n",
    "    word = unicodedata.normalize(\"NFC\", word)\n",
    "    return word\n",
    "\n",
    "def split(line: str) -> list: \n",
    "    words = []\n",
    "    for word in line.split(' '): \n",
    "        if word not in [\"\", \" \"]:\n",
    "            if word[0]==\"\":\n",
    "                word = word.strip(\"'\")\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "def onegrams(file:str) -> dict:\n",
    "    dict_of_onegrams = {}\n",
    "    with open(file, 'r') as lines: \n",
    "        for line in lines:\n",
    "            line = clean(line)\n",
    "            words = split(line)\n",
    "            for word in words: \n",
    "                word = normalize(word)\n",
    "                dict_of_onegrams.setdefault(word, 0)\n",
    "                dict_of_onegrams[word] += 1\n",
    "    return dict_of_onegrams\n",
    "\n",
    "def show_most_common(onegrams: dict, count:int) -> None: \n",
    "    one_grams_sorted = sorted(onegrams.items(), key=lambda item: item[1], reverse=True)\n",
    "    for index, item in enumerate(onegrams_sorted):\n",
    "        if index < count: \n",
    "            print(index + 1, item)\n",
    "\n",
    "if __name__ == \"__main__\": \n",
    "    dict_of_onegrams = onegrams('/paulineclaes/Documents/dta/information_science/InformationScience/course/data/corpus.txt')\n",
    "    show_most_common(dict_of_onegrams,100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
